{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import the data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn import preprocessing\n",
    "\n",
    "# import the data\n",
    "path = 'Audiobooks_data.csv'\n",
    "data_raw = np.loadtxt(path, delimiter = ',')\n",
    "# want all the rows but do not want the first column which is ID and the last colunn which is the target\n",
    "unscaled_data_raw = data_raw[:,1:-1]\n",
    "# want all the rows but only for the last columns which is the target\n",
    "unscaled_targets_raw = data_raw[:,-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Balance Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5\n",
      "0.5\n"
     ]
    }
   ],
   "source": [
    "# need to find out how many rows are in each category, total 1 category\n",
    "total_one_category_count = int(np.sum(unscaled_targets_raw))\n",
    "\n",
    "zero_count = 0\n",
    "indices_remove = []\n",
    "\n",
    "for i in range(unscaled_data_raw.shape[0]):\n",
    "    if unscaled_targets_raw[i] == 0:\n",
    "        zero_count += 1\n",
    "        if zero_count > total_one_category_count:\n",
    "            indices_remove.append(i)\n",
    "            \n",
    "balance_data_raw = np.delete(unscaled_data_raw,indices_remove, axis = 0)\n",
    "balance_target_raw = np.delete(unscaled_targets_raw,indices_remove, axis = 0)\n",
    "\n",
    "# to make sure, the total_one_category_count should be around half of the count of the balanced data and target \n",
    "print(total_one_category_count/balance_data_raw.shape[0])\n",
    "print(total_one_category_count/balance_target_raw.shape[0])\n",
    "\n",
    "# both of them is around 0.50"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Shuffle Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "shuffled_indices = np.arange(balance_data_raw.shape[0])\n",
    "np.random.shuffle(shuffled_indices)\n",
    "\n",
    "shuffle_data = balance_data_raw[shuffled_indices]\n",
    "shuffle_target = balance_target_raw[shuffled_indices]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scale Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaled_data = preprocessing.scale(shuffle_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup training, validation, and test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Count: 3580\n",
      "Testing Count: 447\n",
      "Validation Count: 447\n",
      "validation data percent: 0.09991059454626733\n",
      "testing data percent: 0.09991059454626733\n",
      "training data percent: 0.8001788109074653\n",
      "validation category 1 is : 0.5190156599552572\n",
      "testing category 1 is : 0.5302013422818792\n",
      "training category 1 is : 0.49385474860335193\n"
     ]
    }
   ],
   "source": [
    "# we want 10% of the data to be for validation, 10% for testing, and 80% for training\n",
    "# we reflect that in the counts\n",
    "validation_count = int(scaled_data.shape[0]*0.1)\n",
    "test_count = int(scaled_data.shape[0]*0.1)\n",
    "training_count = int(scaled_data.shape[0]) - validation_count - test_count\n",
    "\n",
    "print ('Training Count: ' + str(training_count))\n",
    "print ('Testing Count: ' + str(test_count))\n",
    "print ('Validation Count: ' + str(validation_count))\n",
    "\n",
    "# we create the data for each training, validaiton, and testing with the preset count\n",
    "# we only want rows for the count we need for each type of datasets\n",
    "\n",
    "validation_data = scaled_data[:validation_count]\n",
    "validation_targets = shuffle_target[:validation_count]\n",
    "\n",
    "test_data = scaled_data[validation_count:validation_count+test_count]\n",
    "test_targets = shuffle_target[validation_count:validation_count+test_count]\n",
    "\n",
    "train_data = scaled_data[validation_count+test_count:]\n",
    "train_targets = shuffle_target[validation_count+test_count:]\n",
    "\n",
    "# we want to make sure that the data is correct\n",
    "# first we make sure that the test and validation data is 10%\n",
    "# and there are 50% of it that are 1 and 50% that are 0\n",
    "\n",
    "print ('validation data percent: '+ str(validation_data.shape[0]/scaled_data.shape[0]))\n",
    "print ('testing data percent: '+ str(test_data.shape[0]/scaled_data.shape[0]))\n",
    "print ('training data percent: '+ str(train_data.shape[0]/scaled_data.shape[0]))\n",
    "\n",
    "print ('validation category 1 is : '+ str(np.sum(validation_targets)/validation_targets.shape[0]))\n",
    "print ('testing category 1 is : '+ str(np.sum(test_targets)/test_targets.shape[0]))\n",
    "print ('training category 1 is : '+ str(np.sum(train_targets)/train_targets.shape[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create NPZ from data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savez('audiobooks_data_train',)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (py3-TF2.0)",
   "language": "python",
   "name": "py3-tf2.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
